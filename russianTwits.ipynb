{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449b4407-5ec9-4ec4-8810-36db52c2e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970443c6-a93e-42c4-94b9-76e44b2c327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_stop_words(text): \n",
    "    words = [porter.stem(word) for word in text.split()] \n",
    "    nostop = [word for word in words if word not in stop]\n",
    "    return \" \".join(nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9039ef-e0f6-4f80-b151-7a3150a76483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "машина ехать быстрый , чем другие машина .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Загрузка русской модели\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "text = \"Машины едут быстрее, чем другие машины.\"\n",
    "doc = nlp(text)\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "print(\" \".join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec903559-17cb-446b-80d3-f51b9c1ce734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(text:str):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba849c-69a7-4106-b295-fe923165091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "porter = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d55be-2e7d-4056-8c9a-ded589d47955",
   "metadata": {},
   "source": [
    "#### Датасет взят c kaggle https://www.kaggle.com/datasets/maximsuvorov/rutweetcorp\n",
    "#### Содержит 200 тыс сообщений из твиттера на на русском языке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6002d-e84c-46ec-818e-b495e77a642a",
   "metadata": {},
   "source": [
    "#### Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e6ddd5-8037-4e38-9810-fc57bc3efa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = pd.read_csv('negative.csv')\n",
    "df_positive = pd.read_csv('positive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abeb1e9-c2fb-4e73-bff7-88e261ce6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_negative.shape)\n",
    "print(df_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f37c88-985e-4492-9244-7f98865da162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410fd22a-5aba-416d-ad6b-20c01fb94c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075cf85-2b02-4d2e-bcc8-4bed32cf0b54",
   "metadata": {},
   "source": [
    "#### Объединим негативные и положительные сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1510e04c-f6ec-4df5-9d56-ce4aff518166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_negative[['ttext','ttype']],df_positive[['ttext','ttype']]])\n",
    "df = df.sample(frac=1)\n",
    "df.index = range(1,df.shape[0]+1)\n",
    "df['ttype'] = df.loc[:,'ttype'].apply(lambda t: 0 if t == -1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b4cb8-d7ba-459d-b086-fcd51a708b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ttype'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750556bc-453e-482d-b6f3-2e126d14a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ttext'].to_csv('mydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07b03e-1ce1-441e-a7b2-d82abf573804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ttype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dfb3859-b19d-44b7-ae2a-4581f2e2221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text:str) -> str :\n",
    "    #text = re.sub(r\"http:\\S*\",\"\",text)\n",
    "    emoticons = re.findall(r\"[XХ:=][3зЗD()]+\", text)\n",
    "    emoticons += re.findall(r\"[0оОoO]_[0оОoO]\", text)\n",
    "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r\"[XХ:][3ЗD()]+\",\"\", text)\n",
    "    text = re.sub(r\"[\\n\\r.,]\",\" \",text)\n",
    "    text = re.sub(r\"[():!;?\\\"|]*\",\"\",text)\n",
    "    text = re.sub(r\"[#@][\\S]*\",\"\",text)\n",
    "    text = re.sub(r\"RT\",\"\",text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r\" {1,}\", \" \",text).strip()\n",
    "    return str.lower(text) +\" \"+\" \".join(emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffe2a0-45ea-48e3-8a4d-d321162a13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions(text:str):\n",
    "    emoticons = re.findall(r\"[XХ:=][3зЗD()]+\", text)\n",
    "    emoticons += re.findall(r\"[0оОoO]_[0оОoO]\", text)\n",
    "    return emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e575f1-20c8-41e8-8599-5ea43715417f",
   "metadata": {},
   "source": [
    "#### На данный момент попытки добавить новые признаки, привело к тому что модель стала смотреть только на них, что ухудшило её качество. Займусь ими позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e53734-4cf1-45df-ba18-e490e3b6d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df['ttext'].iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9207816d-5e75-4bee-8193-75ba9cda3210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аааа я еще не влезала в ленту ну ты просто более чем оригинален Х) :D'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22dde13b-1624-4aba-806a-95cc7cf48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exclamations'] = df['ttext'].apply(lambda l: len(re.findall(r\"!\",l)) > 0)\n",
    "df['sad_bracket'] = df['ttext'].apply(lambda l: len(re.findall(r\"\\(\",l)) > 0)\n",
    "df['happy_bracket'] = df['ttext'].apply(lambda l: len(re.findall(r\"\\)\",l))>0)\n",
    "df['upper_symbols'] = df['ttext'].apply(lambda l: len(list(filter(str.isupper,l)))>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33ab314-2572-425c-ab1e-5b463cbe3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ttext'] = df['ttext'].apply(preprocess)\n",
    "#df['ttext'] = df['ttext'].apply(no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236485b-bd7b-4ad0-93f1-98f042cc4d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69993983-6f92-4110-83ba-255ca6ed7ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf393f2-a6f4-4af9-83ea-66cc672d946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a267058-440b-4c19-baa6-6a04c4535d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['ttext','exclamations','sad_bracket','happy_bracket','upper_symbols']], df['ttype'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7c52d-8ec6-4c64-bb80-45b0785bf671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_log_reg(X_train,y_train):\n",
    "    cv = TfidfVectorizer(ngram_range=(1,2))\n",
    "    sparse_train = cv.fit_transform(X_train['ttext'])\n",
    "    #sparse_tr = scipy.sparse.csr_matrix(X_train[['exclamations','sad_bracket','happy_bracket','upper_symbols']])\n",
    "    #sparse_train = scipy.sparse.hstack([sparse_train,sparse_tr])\n",
    "    \n",
    "    param_grid_logit = {\"C\":[0.1,0.001,10,100,500],'penalty':['l1','l2']}\n",
    "    logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=0)\n",
    "    distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])\n",
    "    clf = RandomizedSearchCV(logistic, distributions, random_state=0,n_jobs=-1)\n",
    "    clf.fit(sparse_train,y_train)\n",
    "    return clf,cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58679933-837a-4f5e-a38a-62473c5844ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train,y_train):\n",
    "    cv = TfidfVectorizer(ngram_range=(1,2))\n",
    "    sparse_train = cv.fit_transform(X_train['ttext'])\n",
    "    #sparse_tr = scipy.sparse.csr_matrix(X_train[['exclamations','sad_bracket','happy_bracket','upper_symbols']])\n",
    "    #sparse_train = scipy.sparse.hstack([sparse_train,sparse_tr])\n",
    "    lg = LogisticRegression(solver='saga',random_state=0,n_jobs=-1)\n",
    "    lg.fit(sparse_train,y_train)\n",
    "    return lg,cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3ec732-f874-41aa-841e-76d2341978f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf,cv = log_reg(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283c14f9-0f58-4451-996a-c1a3217ddd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_test(X_test,y_test,model,cv):\n",
    "    data_clean = prepare_data(X_test,cv)\n",
    "    prediction = model.predict_proba(data_clean)[:,1]\n",
    "    return roc_auc_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5436f7ac-46ad-460c-9e1f-06bb5d8c2350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380411410635925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test(X_test,y_test,clf,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b67b2-01ca-4087-8c4c-289297f04509",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_importance(clf,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252d3c2-2765-48bf-9863-8ada735d9dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c9a34-dcc4-4844-af26-8c28e6eb1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf,cv = random_search_log_reg(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf0296-cb68-41fe-8308-bfa8b7a2a6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"best params\",clf.best_params_)\n",
    "print(\"best score\",clf.best_score_)\n",
    "md = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6a0252-dcac-4caf-88b2-8eb99d41da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df,cv):\n",
    "    #df['exclamations'] = df['ttext'].apply(lambda l: len(re.findall(r\"!\",l)) > 0)\n",
    "    #df['sad_bracket'] = df['ttext'].apply(lambda l: len(re.findall(r\"\\(\",l)) > 0)\n",
    "    #df['happy_bracket'] = df['ttext'].apply(lambda l: len(re.findall(r\"\\)\",l))>0)\n",
    "    #df['upper_symbols'] = df['ttext'].apply(lambda l: len(list(filter(str.isupper,l)))>0)\n",
    "   # df['ttext'] = df['ttext'].apply(preprocess)\n",
    "    sparse_train = cv.transform(df['ttext'])\n",
    "    #sparse_tr = scipy.sparse.csr_matrix(df[['exclamations','sad_bracket','happy_bracket','upper_symbols']])\n",
    "    #sparse_train = scipy.sparse.hstack([sparse_train,sparse_tr])\n",
    "    return sparse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f8170-848f-42c5-a960-d91bf5cb98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(LogisticRegression(n_jobs=-1),param_grid=param_grid_logit,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dd5c9-4390-4064-af33-f852be37a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(sparse_train,df['ttype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e44511-7820-4dfc-accf-27b8659864bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(*clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647de7e1-ddcb-42e5-b406-66468b0e5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba1429-5f8b-4381-abe7-8a2e053202f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b05df0-a207-40d3-a0f2-ebb3fd341928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_importance(model,cv):\n",
    "    words = cv.get_feature_names_out()\n",
    "    coefs = model.coef_[0]\n",
    "    z = list(zip(words,coefs))\n",
    "    z = sorted(z,key=lambda l:l[1],reverse=True)\n",
    "    for el in z[:20]:\n",
    "        print(el)\n",
    "    print(\"----------------\")\n",
    "    for el in z[-20:-1]:\n",
    "        print(el)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d7623-9d24-4b84-82c9-e3a6f9f83d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_i = words_importance(lg,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451be532-ddd4-4e46-be30-e455e0729b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468580d-39c8-42a2-b752-f91a7651f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive = z[:100]\n",
    "most_negative = z[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f27e156-f94c-4e00-a2ea-954289c3c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea44b47-d357-4bef-babb-b16b6c787253",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_positive = WordCloud(background_color=\"black\",\n",
    "                               colormap = 'Blues',\n",
    "                               max_words=200,\n",
    "                               mask=None, \n",
    "                               width=1600,\n",
    "                               height=1600).generate_from_frequencies(dict(most_positive))\n",
    "\n",
    "wordcloud_negative = WordCloud(background_color=\"black\",\n",
    "                               colormap = 'Oranges',\n",
    "                               max_words=200,\n",
    "                               mask=None, \n",
    "                               width=1600,\n",
    "                               height=1600).generate_from_frequencies(dict(most_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344966a-c995-406f-b9a4-de2c65b0f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (20, 12))\n",
    "\n",
    "\n",
    "ax[0].imshow(wordcloud_positive, interpolation='bilinear')\n",
    "ax[1].imshow(wordcloud_negative, interpolation='bilinear')\n",
    "\n",
    "ax[0].set_title('Positive',\n",
    "               fontsize = 20\n",
    "               )\n",
    "ax[1].set_title('Negative',\n",
    "               fontsize = 20\n",
    "               )\n",
    "\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961da8c-d8d7-4a6c-a7d7-e4be9c79bfa2",
   "metadata": {},
   "source": [
    "#### В сообщениях было много грамматических ошибок. На данный момент видно, что признаки были отобраны не совсем удачно. Лемматизацию и стэмминг пока что не применял, со стэммингом вроде еще хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c34b9-81ed-4623-9299-1b1edde1fb8e",
   "metadata": {},
   "source": [
    "#### Сохраним параметры нашей модели. Хочу сделать небольшой прод в виде тг бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10206e19-2658-42b6-974f-41c7f3637b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb305eca-ca2e-415a-87da-9b148a3eb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pkl', 'wb') as file:\n",
    "    pickle.dump(lg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f923dc-95fd-4a9b-9ec0-48183426fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer2.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d214cc7-bd58-45e0-af4c-3031edc63b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb120f-75d7-4677-bfe3-a5ea9c5f5660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1151d7-c096-47e9-839a-675312c0c81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba03dd6-86e7-4cd6-945a-9be0c5f664e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.fit(sparse_train,df['ttype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e5760-3e4f-4d8c-9534-3244aa5eb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd76c7-4629-415e-badd-fc7e39805623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
